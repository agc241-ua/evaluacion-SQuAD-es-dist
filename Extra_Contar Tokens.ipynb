{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7nhQxEvVGTDzCsP4PdruS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6Z-neQtKC2UQ"},"outputs":[],"source":["!pip install -U spacy"]},{"cell_type":"code","source":["import spacy\n","from spacy import displacy\n","from collections import Counter\n","import pandas as pd\n","import json\n","pd.set_option(\"display.max_rows\", 400)\n","pd.set_option(\"display.max_colwidth\", 400)"],"metadata":{"id":"GF-SdwF2DAAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python -m spacy download es_core_news_md"],"metadata":{"id":"DZZ5IkfHDD8m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load('es_core_news_md')"],"metadata":{"id":"3YNn3SvVDqD4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"training_ids.json\", \"r\", encoding=\"utf-8\") as f:\n","    data1 = json.load(f)"],"metadata":{"id":"SCaI13zdJ278"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"dev.json\", \"r\", encoding=\"utf-8\") as f:\n","    data = json.load(f)"],"metadata":{"id":"kLN6qaLcgc2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CONTEXTOS!!!\n","resultados = []\n","for item in data[\"data\"]:\n","  contexto = item[\"context\"]\n","  #id = item[\"id\"]\n","  doc = nlp(contexto)\n","  #número de tokens\n","  tokens = [t for t in doc if not t.is_punct and not t.is_space]\n","  total_tokens = len(tokens)\n","  pos_counts = Counter([t.pos_ for t in tokens])\n","\n","  resultados.append({\n","      #\"id\": id,\n","      \"total_palabras\": total_tokens,\n","      \"sustantivos (NOUN)\": pos_counts.get(\"NOUN\", 0),\n","      \"adjetivos (ADJ)\": pos_counts.get(\"ADJ\", 0),\n","      \"verbos (VERB)\": pos_counts.get(\"VERB\", 0),\n","      \"adverbios (ADV)\": pos_counts.get(\"ADV\", 0)\n","  })\n","\n","with open(\"tokens_context_dev.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(resultados, f, indent=4, ensure_ascii=False)\n","\n","df = pd.DataFrame(resultados)\n","# print(df)\n","\n","#Calcular medias:\n","media_palabras = df[\"total_palabras\"].mean()\n","media_sustantivos = df[\"sustantivos (NOUN)\"].mean()\n","media_adjetivos = df[\"adjetivos (ADJ)\"].mean()\n","media_verbos = df[\"verbos (VERB)\"].mean()\n","media_adverbios = df[\"adverbios (ADV)\"].mean()\n","\n","\n","print(\"\\n--- Medias ---\")\n","print(f\"Media de total de palabras: {media_palabras}\")\n","print(f\"Media de sustantivos (NOUN): {media_sustantivos:.2f}\")\n","print(f\"Media de adjetivos (ADJ): {media_adjetivos:.2f}\")\n","print(f\"Media de verbos (VERB): {media_verbos:.2f}\")\n","print(f\"Media de adverbios (ADV): {media_adverbios:.2f}\")\n","\n","# Máximo número de tokens y mínimo:\n","max_idx = df[\"total_palabras\"].idxmax()\n","min_idx = df[\"total_palabras\"].idxmin()\n","\n","print(\"\\n--- Contexto con más palabras ---\")\n","print(f\"Índice: {max_idx}, Total de palabras: {df.loc[max_idx, 'total_palabras']}\")\n","print(\"Contexto:\", data[\"data\"][max_idx][\"context\"])\n","\n","print(\"\\n--- Contexto con menos palabras ---\")\n","print(f\"Índice: {min_idx}, Total de palabras: {df.loc[min_idx, 'total_palabras']}\")\n","print(\"Contexto:\", data[\"data\"][min_idx][\"context\"])"],"metadata":{"id":"OvcGfYceDmQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PREGUNTAS!!!\n","resultadosQuest = []\n","for item in data[\"data\"]:\n","  pregunta = item[\"question\"]\n","  #id = item[\"id\"]\n","  doc = nlp(pregunta)\n","  #número de tokens\n","  tokens = [t for t in doc if not t.is_punct and not t.is_space]\n","  total_tokens = len(tokens)\n","  pos_counts = Counter([t.pos_ for t in tokens])\n","\n","  resultadosQuest.append({\n","      #\"id\": id,\n","      \"total_palabras\": total_tokens,\n","      \"sustantivos (NOUN)\": pos_counts.get(\"NOUN\", 0),\n","      \"adjetivos (ADJ)\": pos_counts.get(\"ADJ\", 0),\n","      \"verbos (VERB)\": pos_counts.get(\"VERB\", 0),\n","      \"adverbios (ADV)\": pos_counts.get(\"ADV\", 0)\n","  })\n","\n","with open(\"tokens_question_training.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(resultadosQuest, f, indent=4, ensure_ascii=False)\n","\n","df = pd.DataFrame(resultadosQuest)\n","# print(df)\n","\n","#Calcular medias:\n","media_palabras = df[\"total_palabras\"].mean()\n","media_sustantivos = df[\"sustantivos (NOUN)\"].mean()\n","media_adjetivos = df[\"adjetivos (ADJ)\"].mean()\n","media_verbos = df[\"verbos (VERB)\"].mean()\n","media_adverbios = df[\"adverbios (ADV)\"].mean()\n","\n","\n","print(\"\\n--- Medias ---\")\n","print(f\"Media de total de palabras: {media_palabras}\")\n","print(f\"Media de sustantivos (NOUN): {media_sustantivos:.2f}\")\n","print(f\"Media de adjetivos (ADJ): {media_adjetivos:.2f}\")\n","print(f\"Media de verbos (VERB): {media_verbos:.2f}\")\n","print(f\"Media de adverbios (ADV): {media_adverbios:.2f}\")\n","\n","# Máximo número de tokens y mínimo:\n","max_idx = df[\"total_palabras\"].idxmax()\n","min_idx = df[\"total_palabras\"].idxmin()\n","\n","print(\"\\n--- Contexto con más palabras ---\")\n","print(f\"Índice: {max_idx}, Total de palabras: {df.loc[max_idx, 'total_palabras']}\")\n","print(\"Contexto:\", data[\"data\"][max_idx][\"context\"])\n","\n","print(\"\\n--- Contexto con menos palabras ---\")\n","print(f\"Índice: {min_idx}, Total de palabras: {df.loc[min_idx, 'total_palabras']}\")\n","print(\"Contexto:\", data[\"data\"][min_idx][\"context\"])"],"metadata":{"id":"QlzKGCR4Ecpe"},"execution_count":null,"outputs":[]}]}